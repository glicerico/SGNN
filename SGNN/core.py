# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['data_filepath', 'data', 'char_ngram_range', 'char_term_frequency_params', 'T', 'd', 'rand_seeds',
           'hashing_feature_union_params']

# Cell
import pandas as pd

data_filepath = 'data/swda-acttags-and-text.csv'
data = pd.read_csv(data_filepath)

# Cell

# CountVectorizer Parameters
char_ngram_range = (1, 4)

char_term_frequency_params = {
    'char_term_frequency__analyzer': 'char',
    'char_term_frequency__lowercase': True,
    'char_term_frequency__ngram_range': char_ngram_range,
    'char_term_frequency__strip_accents': None,
    'char_term_frequency__min_df': 2,
    'char_term_frequency__max_df': 0.99,
    'char_term_frequency__max_features': int(1e7),
}

# Cell
import scipy.sparse as sp
import random as rand

T = 80
d = 14
# T=80 projections for each of dimension d=14: 80 * 14 = 1120-dimensionnal word projections
rand_seeds = [rand.randint(0,T*100) for i in range(T)] # Need a different seed for each hasher

hashing_feature_union_params = {
    **{'union__random_binary_projection_hasher_{}__projection_count'.format(t): d
       for t in range(T)
    },
    **{'union__random_binary_projection_hasher_{}__hash_name'.format(t): 'hasher' + str(t)
       for t in range(T)
    },
    **{'union__random_binary_projection_hasher_{}__rand_seed'.format(t): rand_seeds[t]  # only AFTER hashing.
       for t in range(T)
    }
}